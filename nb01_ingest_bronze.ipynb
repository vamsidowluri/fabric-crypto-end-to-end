{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","\n","import requests\n","import json\n","import os\n","from datetime import datetime\n","\n","# --- CONFIGURATION ---\n","# The URL for real-time crypto market data (USD prices, market cap, volume)\n","API_URL = \"https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&order=market_cap_desc&per_page=100&page=1&sparkline=false\"\n","\n","# --- HELPER FUNCTIONS ---\n","def get_api_data(url):\n","    \"\"\"\n","    Connects to the API and returns the raw JSON data.\n","    \"\"\"\n","    try:\n","        response = requests.get(url)\n","        response.raise_for_status() # Check if the request was successful\n","        return response.json()\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error fetching data: {e}\")\n","        return None\n","\n","def save_to_lakehouse(data, folder_name=\"crypto_raw\"):\n","    \"\"\"\n","    Saves the JSON data to the Lakehouse 'Files' section (Bronze Layer).\n","    \"\"\"\n","    # 1. Create a filename with the current timestamp\n","    # This ensures we don't overwrite old data (History preservation)\n","    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    file_name = f\"crypto_data_{current_time}.json\"\n","    \n","    # 2. Define the path. \n","    # \"/lakehouse/default/Files/\" is the standard path to your attached Lakehouse\n","    folder_path = f\"/lakehouse/default/Files/bronze/{folder_name}\"\n","    full_path = f\"{folder_path}/{file_name}\"\n","\n","    # 3. Ensure the folder exists\n","    os.makedirs(folder_path, exist_ok=True)\n","\n","    # 4. Write the file\n","    with open(full_path, \"w\") as f:\n","        json.dump(data, f)\n","    \n","    print(f\"SUCCESS: Data saved to {full_path}\")\n","\n","# --- MAIN EXECUTION ---\n","print(\"Starting ingestion...\")\n","data = get_api_data(API_URL)\n","\n","if data:\n","    save_to_lakehouse(data)\n","    print(\"Ingestion complete.\")\n","else:\n","    print(\"Ingestion failed.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"5f37d996-7631-4410-ab01-0075910fe426","normalized_state":"finished","queued_time":"2026-01-19T05:40:19.8735845Z","session_start_time":"2026-01-19T05:40:19.8746007Z","execution_start_time":"2026-01-19T05:40:29.7262295Z","execution_finish_time":"2026-01-19T05:40:32.7407535Z","parent_msg_id":"936c462a-b9d0-4e89-b6d3-927ed22d981f"},"text/plain":"StatementMeta(, 5f37d996-7631-4410-ab01-0075910fe426, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting ingestion...\nSUCCESS: Data saved to /lakehouse/default/Files/bronze/crypto_raw/crypto_data_20260119_054030.json\nIngestion complete.\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cd8c7990-edc9-4ac3-a4f9-aeb14676e526"},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","from datetime import datetime\n","from notebookutils import mssparkutils\n","\n","# ==============================================================================\n","# 1. CONFIGURATION\n","# ==============================================================================\n","# PASTE YOUR PATH INSIDE THESE QUOTES üëá\n","LAKEHOUSE_ROOT_PATH = \"abfss://DE_Project_Portfolio@onelake.dfs.fabric.microsoft.com/Lh_Medallion.Lakehouse/Files\"\n","\n","API_URL = \"https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd&order=market_cap_desc&per_page=100&page=1&sparkline=false\"\n","\n","# ==============================================================================\n","# 2. THE INGESTION LOGIC\n","# ==============================================================================\n","def get_api_data(url):\n","    try:\n","        response = requests.get(url)\n","        response.raise_for_status()\n","        return response.json()\n","    except Exception as e:\n","        print(f\"API Error: {e}\")\n","        return None\n","\n","def save_to_onelake(data, root_path):\n","    # Create filename with timestamp\n","    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    file_name = f\"crypto_data_{current_time}.json\"\n","    \n","    # Construct the FULL OneLake URL\n","    # We manually build the path: Root -> bronze folder -> crypto_raw folder -> file\n","    full_path = f\"{root_path}/bronze/crypto_raw/{file_name}\"\n","\n","    print(f\"Attempting to write to: {full_path}\")\n","\n","    # Write using Microsoft Spark Utilities (The \"Cloud Native\" way)\n","    try:\n","        mssparkutils.fs.put(full_path, json.dumps(data), True)\n","        print(\"‚úÖ SUCCESS! File written to OneLake.\")\n","        return full_path\n","    except Exception as e:\n","        print(\"‚ùå WRITE ERROR: Could not save to OneLake.\")\n","        print(e)\n","        return None\n","\n","# ==============================================================================\n","# 3. EXECUTION & VERIFICATION\n","# ==============================================================================\n","print(\"Starting Ingestion...\")\n","\n","data = get_api_data(API_URL)\n","\n","if data:\n","    saved_path = save_to_onelake(data, LAKEHOUSE_ROOT_PATH)\n","\n","    # Double check: List the file immediately to prove it exists\n","    if saved_path:\n","        print(\"\\n--- üëÄ VERIFYING FILE EXISTS IN STORAGE ---\")\n","        try:\n","            folder = f\"{LAKEHOUSE_ROOT_PATH}/bronze/crypto_raw\"\n","            files = mssparkutils.fs.ls(folder)\n","            for f in files:\n","                print(f\"Confirmed file found: {f.name}\")\n","        except Exception as e:\n","            print(f\"Verification failed: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"5f37d996-7631-4410-ab01-0075910fe426","normalized_state":"finished","queued_time":"2026-01-19T05:50:31.475658Z","session_start_time":null,"execution_start_time":"2026-01-19T05:50:31.4769655Z","execution_finish_time":"2026-01-19T05:50:33.8573093Z","parent_msg_id":"d67f0f9c-b2d5-4f3d-b201-6fbe36bfaf15"},"text/plain":"StatementMeta(, 5f37d996-7631-4410-ab01-0075910fe426, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting Ingestion...\nAttempting to write to: abfss://DE_Project_Portfolio@onelake.dfs.fabric.microsoft.com/Lh_Medallion.Lakehouse/Files/bronze/crypto_raw/crypto_data_20260119_055032.json\n‚úÖ SUCCESS! File written to OneLake.\n\n--- üëÄ VERIFYING FILE EXISTS IN STORAGE ---\nConfirmed file found: crypto_data_20260119_055032.json\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5c29e0d-c1ff-4be5-8058-7fb1883768bd"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}